% weights could be calculated from conditional probabilities, Experiment 2
In this thesis a spiking Winner-Take-All neural network model which was taken from \citet{nessler} and expanded by a neuron layer of prior neurons was used. This model is partially based on the hypothesis, that the weights of the network, due to STDP-induced changes, converge stochastically to the log of the conditional probability that a presynaptic neuron has fired shortly before the postsynaptic neuron. This relation, given in Equation \ref{eqn:weightProbLink}, was proven in Experiment 2. The likelihood $P(X=x|Y=k)$, the prior $P(Y=k|Z=j)$ and the posterior $P(Y = k|X, Z)$ were analytically calculated. Then the input weights were derived from the likelihood and the prior weights were derived from the prior. Then the network was simulated and its output was used to calculate the posterior of the simulation. The Kullback-Leibler divergence between the analytically calculated posterior and the posterior of the simulation was calculated to evaluate how closely the simulation was able to approximate the optimal analytical solution. The results of the best hyperparameter set are given in Figure \ref{fig:1D_98_440_4} and Table \ref{tab:1D_98_440_4}. The simulation approximated the analytical solution closely and it can be concluded that the hypothesis of Equation \ref{eqn:weightProbLink} was correct. However, it was not possible to tune the network to perfectly match the analytical solution.
% welche probleme hatte Exp 2 und warum konnte es optimum nicht perfekt approximaten?
%1. wegen nicht normalisiertem U? Aber laut mir sollte das doch passen, da es mit der Stochastik zusammenpasst....

%2. wegen nicht geteilten c ... das machts viel schwieriger perfekt zu trainieren. ... aber das trifft hier nicht zu, da nichts trainiert wurde!!!





%link between bayesian inference posterior probab and relative firing probability q_k



This thesis provides evidence that a spiking Winner-Take-All neural network can recreate behaviours that were observed in the visual cortex. Neural feedback is most commonly associated with attention. Such attention behaviour could be shown in Experiment 1, where ambiguous cross images were shown to the network. Without the feedback and if the output neurons would have learned the optimal solution, where each neuron had active areas of the same sizes and relative activities of 0.5 in the border areas, then the network would have not known which part of the cross image to focus on. In reality the output neurons ended up with different sized active areas and unequal relative activities. Due to that, when both parts of the cross were exactly in the middle of the theoretical centers of two output neurons, one output neuron was more active than the other, signifying attention on the corresponding part of the cross. However, this unequal learning of the output neurons could be countered by the activity of the prior neurons that delivered feedback. If the prior activity was set to "horizontal" the corresponding output neuron was always more active than its vertical counterpart. As shown by \citet{HierachicalBayesVisualCortex} feedback from the inferior temporal cortex to V1 is able to convince V1 into "seeing" illusory lines. This behaviour was reproduced in Experiment 2. Figures \ref{fig:1D_88_0_4} and \ref{fig:1D_88_440_4} show the validation results of the same network with the same hyperparameter set, except once with disabled prior neurons and once with enabled ones. The sixth input image has active pixels at positions 1, 2 and 3. Thus it lies in the middle between classes 1 and 2. When looking at Figure \ref{fig:1D_88_0_4} A6 & B6 it can be seen that with disabled prior neurons most of the output activity originates from $y_1$ and $y_2$, the output of the network  matches the visual input. In Figure \ref{fig:1D_88_440_4} with a prior that signals class 4 in subfigures A6 & B6 it can be seen that the output probabilities shifted. The most active output neuron now is $y_4$, while $y_1$ and $y_2$ have smaller output probabilities. $y_4$ being the most active neuron contradicts the visual input, but it is boosted by the prior information it receives. This by feedback induced belief matches the experimental evidence of the visual cortex.



%4. why were the parameters not transferable to bigger network. Why would they even be in the first place? They were not transferable, as we saw in experiment 2 increasing f_input changes the conditional probabilities.

% why training Exp4 sucked

\subsection{Future work}
%2. Future work: 
%a. Normalization of U? mby, but it actually makes more sense how it is right now wegen stochastic samples ziehen
%b. implement a prior that is actually influenced by network activity
%c. separate weight shift parameter for input and prior weights. maybe weight shift parameter depending on number of neurons and firing frequency


