In this thesis a spiking Winner-Take-All neural network model which was taken from \citet{nessler} and expanded by a neuron layer of prior neurons was used. This model is partially based on the hypothesis, that the weights of the network, due to STDP-induced changes, converge stochastically to the log of the conditional probability that a presynaptic neuron has fired shortly before the postsynaptic neuron. This relation, given in Equation \ref{eqn:weightProbLink}, was proven in Experiment 2. The likelihood $P(X=x|Y=k)$, the prior $P(Y=k|Z=j)$ and the posterior $P(Y = k|X, Z)$ were analytically calculated. Then the input weights were derived from the likelihood and the prior weights were derived from the prior. Then the network was simulated and its output was used to calculate the posterior of the simulation. The Kullback-Leibler divergence between the analytically calculated posterior and the posterior of the simulation was calculated to evaluate how closely the simulation was able to approximate the optimal analytical solution. The results of the best hyperparameter set are given in Figure \ref{fig:1D_98_440_4} and Table \ref{tab:1D_98_440_4}. The simulation approximated the analytical solution closely and it can be concluded that the hypothesis of Equation \ref{eqn:weightProbLink} was correct. However, it was not possible to tune the network to perfectly match the analytical solution. One difficulty when tuning the network was explained in Subsection \ref{subsection:impactHyper}. Increasing or decreasing $f_input$ had an unexpected effect of changing the probability density function of the relative output firing probability $q_k$. From a stochastic point of view this effect made sense, as more generated input spikes can be interpreted as pulling more samples from the likelihood probability distribution. By that the standard error of the posterior probability distribution is reduced, which then reduces the width of its probability density function. This means that the higher $f_{input}$ gets,  the more certain the network becomes of the most likely output class. As the prior neurons contribute to the membrane potential in the same way as the input neurons it was suspected that the same effect occurs when $f_{prior}$ is increased. However, it was impossible to observe it directly as increasing $f_{prior}$ already has the effect of shifting the probability density function of the posterior by design, making the two effects indistinguishable from each other. However, it is unclear why the analytic posterior could not be approximated closer, as the impacts of $f_{input}$, as well as $f_{prior}$ seemed correct.
Another hypothesis the network model is based on is that $q_k$ is equal to the posterior probability $P(Y = k|X, Z)$. This relation was explained in Subsection \ref{linkNetworkBayes} and found conclusive.

Evidence that a spiking Winner-Take-All neural network can recreate behaviours that were observed in the visual cortex. Neural feedback is most commonly associated with attention. Such attention behaviour could be shown in Experiment 1, where ambiguous cross images were shown to the network. Without the feedback and if the output neurons would have learned the optimal solution, where each neuron had active areas of the same sizes and relative activities of 0.5 in the border areas, then the network would have not known which part of the cross image to focus on. In reality the output neurons ended up with different sized active areas and unequal relative activities. Due to that, when both parts of the cross were exactly in the middle of the theoretical centers of two output neurons, one output neuron was more active than the other, signifying attention on the corresponding part of the cross. However, this unequal learning of the output neurons could be countered by the activity of the prior neurons that delivered feedback. If the prior activity was set to "horizontal" the corresponding output neuron was always more active than its vertical counterpart. As shown by \citet{HierachicalBayesVisualCortex} feedback from the inferior temporal cortex to V1 is able to convince V1 into "seeing" illusory lines. This behaviour was reproduced in Experiment 2. Figures \ref{fig:1D_88_0_4} and \ref{fig:1D_88_440_4} show the validation results of the same network with the same hyperparameter set, except once with disabled prior neurons and once with enabled ones. The sixth input image has active pixels at positions 1, 2 and 3. Thus it lies in the middle between classes 1 and 2. When looking at Figure \ref{fig:1D_88_0_4} A6 & B6 it can be seen that with disabled prior neurons most of the output activity originates from $y_1$ and $y_2$, the output of the network  matches the visual input. In Figure \ref{fig:1D_88_440_4} with a prior that signals class 4 in subfigures A6 & B6 it can be seen that the output probabilities shifted. The most active output neuron now is $y_4$, while $y_1$ and $y_2$ have smaller output probabilities. $y_4$ being the most active neuron contradicts the visual input, but it is boosted by the prior information it receives. This by feedback induced belief matched the experimental evidence of the visual cortex.

The possibility to reuse a hyperparameter set for a network of different size was examined in Experiment 3. In this experiment the number of input neurons, the prior firing frequency and the size of the input images was doubled. The weights were re-calculated accordingly to the bigger size. The Kullback-Leibler divergence of this experiment was 0.2392 compared to 0.0101 of the original network. This clearly showed that the hyperparameters could not simply be reused for a network of different size. One possible reason for this could be the, already discussed, effect of different $f_input$ changing the probability density function of $q_k$. By doubling the number of input neurons twice as many samples were pulled from the input probability distribution, which made the network prefer output classes with more active pixels within their active areas over output classes with fewer active pixels. Furthermore, the impact of the prior neurons was too high. As already discussed the exponential dependency of $q_k$ on $u_k$ might have caused this increased impact of the prior neurons. For each validation image only one of the four output neurons received EPSPs from the prior neurons, when noise is disregarded. By raising its $u_k$ to the power of e its proportion to the other membrane potentials gets much larger than before the doubling of $f_{prior}$. This increased impact of the prior neurons is suspected to be the main reason to why the transfer of the hyperparameters performed poorly.

In Experiment 4 the best hyperparameter set that was determined in Experiment 2 was used to train the input and prior weights of the network.
%2. wegen nicht geteilten c ... das machts viel schwieriger perfekt zu trainieren
% nachschauen wie groß die input/prior weights im vergleich sind. Wenn eine größer dann stimmt das mitm c fix. , ja prior weights waren zu hoch, während die input weights noch zu klein waren

\subsection{Future work}
%2. Future work: 
%a. Normalization of U? mby, but it actually makes more sense how it is right now wegen stochastic samples ziehen. Das genauer analysieren
%b. implement a prior that is actually influenced by network activity (= more complex network)
%c. separate weight shift parameter for input and prior weights. maybe weight shift parameter depending on number of neurons and firing frequency


