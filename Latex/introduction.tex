The brain needs to handle a high degree of uncertainty in sensory input. When it first receives input it does not know what the information could represent, thus not knowing which parts of the input are most relevant. Traditional views of the visual pathway of the brain hypothesized that the sensory input is passed on from lower to higher visual areas in a feed-forward system. However, \citet{HierachicalBayesVisualCortex} shows  neurophysiological experimental evidence that there is feedback from high-level to low-level areas of the visual cortex. That feedback information is thought to be "explaining away" information, or putting emphasis on specific information of the low-level area. Several experiments on animals show that the cerebral cortex utilizes Bayesian inference to compute information like sensory input \citep{neuralSubstrate, HierachicalBayesVisualCortex, anatomyOfInference}. They hypothesize that the brain functions as a generative (probabilistic) model to reach its conclusions. This means the brain expresses information via probability distributions, rather than utilizing static neural codes. Bayes theorem yields a posterior probability, by multiplying the likelihood with the prior probability. In the context of cortical computation the posterior is represented by the output of a neural network and the likelihood is represented by its input. The feedback from high-level to low-level cortical areas can be interpreted as the prior probability.

Different models for the computational simulation of neural networks exist  \citep{SpikingNeuronModelsBook}. The plasticity of neural networks is often modelled as Spike-timing-dependent plasticity (STDP), as it agrees with biological experiments \citep{STDPFELDMAN, STDPDAN}. 

To select the output of a neural network a soft Winner-Take-All mechanism is often applied. It chooses what is information is forwarded vertically into another layer in inhibits its horizontal neighbours of the same layer.  This mechanism resembles the way biological pyramidal neurons function \citep{softWTA}. Furthermore Winner-Take-All modules have a higher computational power than threshold-gates \citep{WTAPower}.

\citet{nessler} and \citet{nesslerClone} created Winner-Take-All spiking neural networks which perform Bayesian inference. The hierarchical network model of \citet{nessler} is used and expanded in this thesis to simulate the feedback from a high visual cortex area to a lower area.