Functional networks of the human brain have a hierarchical modular organization. This means the execution of one specific task, for example vision, involves several modules which are interconnected  \citep{hierarchicalBrain}. Traditional views of the visual pathway of the brain hypothesized that the sensory input is passed on from lower to higher visual areas in a feed-forward system. However, \citet{HierachicalBayesVisualCortex} shows  neurophysiological experimental evidence that there is feedback from high-level to low-level areas of the visual cortex. That feedback information is thought to be "explaining away" information, or putting emphasis on specific information of the low-level area. 
 
The brain needs to handle a high degree of uncertainty in sensory input. When it first receives input it does not know what the information could represent, thus not knowing which parts of the input are most relevant. Several experiments on animals show that the cerebral cortex utilizes Bayesian inference to compute information like sensory input \citep{neuralSubstrate, HierachicalBayesVisualCortex, anatomyOfInference}. They hypothesize that the brain functions as a generative (probabilistic) model to reach its conclusions. This means the brain expresses information via probability distributions, rather than utilizing static neural codes. Bayes theorem yields a posterior probability, by multiplying the likelihood with the prior probability. In the context of cortical computation the posterior is represented by the output of a neural network and the likelihood is represented by its input. The feedback from high-level to low-level cortical areas can be interpreted as the prior probability.

Different models for the computational simulation of neural networks exist  \citep{SpikingNeuronModelsBook}. The plasticity of neural networks is often modelled as Spike-timing-dependent plasticity (STDP), as it agrees with biological experiments \citep{STDPFELDMAN, STDPDAN}. 

To select the output of a neural network a soft Winner-Take-All mechanism is often applied. It chooses what is information is forwarded vertically into another layer in inhibits its horizontal neighbours of the same layer.  This mechanism resembles the way biological pyramidal neurons function \citep{softWTA}. Furthermore Winner-Take-All modules have a higher computational power than threshold-gates \citep{WTAPower}.

\citet{nessler} and \citet{nesslerClone} created Winner-Take-All spiking neural networks which perform Bayesian inference. Both of those works did not include feedback that comes from a network higher up in the hierarchy. As such feedback is proven to exist by experiments this thesis aims to expand the model. The hierarchical network model of \citet{nessler} is taken and expanded to simulate a functional neural network that receives visual input and also feedback from another network higher up in the hierarchy.

In Chapter 2 the biological background for this thesis and the underlying hierarchical spiking Winner-Take-All network will be given. The theoretical background, explaining the mathematical model used for the neural networks in this thesis, will be explained in Chapter 3. (Chapter 4 is a work in progress). Finally, in Chapter 5, the results of the experiments will be summarized and their implications will be discussed.