Functional networks of the human brain have a hierarchical modular organization. This means the execution of one specific task, for example vision, involves several modules which are interconnected  \citep{hierarchicalBrain}. Traditional views of the visual pathway of the brain hypothesized that the sensory input is passed on from lower to higher visual areas in a feed-forward system. However, \citet{HierachicalBayesVisualCortex} shows  neurophysiological experimental evidence that there is feedback from high-level to low-level areas of the visual cortex. That feedback information is thought to be "explaining away" information, or putting emphasis on specific information of the low-level area. Through this mechanism can attention be realized and different cortex areas are able to adopt the same interpretation of some input.
 
The brain needs to handle a high degree of uncertainty in sensory input. When it first receives input it does not know what the information could represent, thus not knowing which parts of the input are most relevant. Several experiments on animals show that the computation of sensory input that the cerebral cortex performs can be explained and modelled by Bayesian inference \citep{neuralSubstrate, HierachicalBayesVisualCortex, anatomyOfInference}. They hypothesize that the brain functions as a generative and probabilistic model to reach its conclusions. This means the brain expresses information via probability distributions, rather than utilizing static neural codes. Bayes theorem yields a posterior probability, by multiplying a likelihood with a prior probability. In the context of cortical computation one can postulate that the posterior is represented by the output of a neural network. The likelihood can be computed based on the sensory input to the network and the feedback it receives from other cortical areas. The feedback from high-level to low-level cortical areas can be modelled as the prior probability \citep{nessler}.

There are various models for the computational dynamics of biological neurons \citep{SpikingNeuronModelsBook}. 

%TODO
%1. discuss spiking neurons
%2. discuss briefly synaptic plasticity
%3. explain synaptic plasticity in biological background

The plasticity of neural networks is often modelled as Spike-timing-dependent plasticity (STDP), as it agrees with biological experiments \citep{STDPFELDMAN, STDPDAN}. 

TODO!!!!!!!
1. Talk about the canonical cortical microcircuit (softWTA paper douglas)
2. Say that WTA was postulated as a key computational motif
To select the output of a neural network the soft Winner-Take-All mechanism is well established. Neurons with this mechanism choose what information is forwarded vertically into another layer and inhibit their horizontal neighbours of the same layer.  This mechanism resembles the way biological pyramidal neurons function \citep{softWTA}. Furthermore Winner-Take-All modules have a higher computational power than threshold-gates \citep{WTAPower}.

\citet{nessler} and \citet{nesslerClone} created Winner-Take-All spiking neural networks which perform Bayesian inference. Both of those works did not include feedback that comes from a network higher up in the hierarchy. As such feedback is proven to exist by experiments this thesis aims to expand the model. The hierarchical network model of \citet{nessler} is taken and expanded to simulate a functional neural network that receives visual input and also feedback from another network higher up in the hierarchy.
%TODO:
%1. summarize what we do and the main results


In Chapter 2 the biological background for this thesis and the underlying hierarchical spiking Winner-Take-All network will be given. The theoretical background, explaining the mathematical model used for the neural networks in this thesis, will be explained in Chapter 3. (Chapter 4 is a work in progress). Finally, in Chapter 5, the results of the experiments will be summarized and their implications will be discussed.