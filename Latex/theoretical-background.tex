\section{Spiking neural networks}

Spiking neural networks (SNNs) are artificial neural networks that resemble biological neural networks more closely. Neurons in typical neural networks used in machine learning transmit information at every propagation cycle. This, however, is not how biological neurons operate. They generate action potentials (neuron spikes) to convey information between each other. These action potentials are only generated when their membrane potential exceeds a threshold. SNN models take this behaviour into account by keeping track of each neurons membrane potential and then determining when they should produce an action potential  \citep{SpikingNeuronModelsBook}.

Previously it was believed that biological neural networks encode information within the spike rates of neurons. However neurobiological research shows evidence that at high speed processing this alone can not be sufficient. For example image recognition tasks can be performed at a speed at which each neuron in the involved layers has only less than 10 ms to process the information. Such a time frame is too short for rate coding to occur. Instead it has been shown that high speed processing tasks can be performed using the precise timing of spikes. Furthermore it requires more energy for a neuron to spike many times to express a spike rate, rather than spiking just once and having the timing of the spike considered. As the brain evolutionary aims to minimize its energy consumption this is a strong argument for spike timing encoded information. Also the information encoding capacity is higher in a small set of spiking neurons, compared to rate encoding. \citep{LearningInBiologicallyPlausibleSNN}
Because of that Spike Timing Dependent Plasticity (STDP) is often used as learning rule in SNNs. STDP models the synaptic weight changes of neurons depending on the relative timing of pre- and postsynaptic spikes. If a presynaptic spike arrives shortly before the postsynaptic spike the synaptic weight is increased. The size of that increase depends exponentially on the time between both spikes, according to a time constant. However, when the presynaptic spike occurs after the postsynaptic spike the synaptic weight is decreased. These two mechanisms are called long-term potentiation and long-term depression respectively. Although STDP is often modelled like this, biological experiments show that the standard pair-based approach does not fully explain it in biological neurons. 
\citep{LearningInBiologicallyPlausibleSNN}	

\section{Bayes' theorem}

Bayes' theorem describes the probability of an event to occur, depending on the prior knowledge of conditions related to the event \citep{bayesBasic}. 
\begin{equation}
\label{eqn:bayesianTheorem}
P(A|B) = \frac{P(B|A)P(A)}{P(B)}.
\end{equation}
P(A|B) is the posterior probability of A given that B is true. P(B|A) is called conditional probability of B given A being true. P(A) is the prior probability, the probability of A occurring without any additional information. Finally P(B) is the marginal probability of B without any given condition. This theorem is often used for Bayesian inference where it expresses how a belief, which is represented as probability changes due to related evidence.	

\section{Bayesian inference}
\label{section:bayesianInference}

Bayesian inference is a process of data analysis to calculate the probability of a hypothesis depending on the available related evidence. As over time more and more evidence becomes available the probabilities can be updated yielding a more sophisticated view on the hypothesis. It is given, according to Bayes' theorem, by
\begin{equation}
\label{eqn:bayesianInference}
P(H|E) = \frac{P(E|H)P(H)}{P(E)},
\end{equation}
where H represents a hypothesis and E some related evidence. P(H|E) is the posterior probability which signifies the probability of the hypothesis after the evidence was observed. P(E|H) is called likelihood and it is the probability of observing the evidence 	given the hypothesis. It is a measure of the compatibility of the observed evidence with the given hypothesis. P(H) is the prior probability which is the probability of the hypothesis before any evidence is considered or obtained. P(E) is called marginal likelihood that represents the probability of the evidence being observed. However it is the same independent of the chosen hypothesis. Thus, it is not factored in when comparing different hypotheses.
Bayesian inference could be applied to the "face in shadow" example of Section \ref{section:feedbackInVisualCortex}. There a neuron sees a small part of the visual field and signals if it sees an edge or not. At first it has the evidence of the observed pixels available and from it can calculate the likelihood that an edge is present. Together with the prior knowledge of how probable an edge being present is, it can conclude the posterior probability for the hypothesis "there is an edge". Later when the related evidence that there is a face in the picture is being fed back from the inferior temporal cortex this additional information updates the posterior probability. The additional evidence $E_2$ that is being fed back can be added to the calculation by
\begin{equation}
\label{eqn:bayesianInference}
P(H|E_2) = \frac{P(E_2|E)P(E|H)P(H)}{P(E_2)}.
\end{equation}
\citep{bayesInferenceBook}

\section{Connection between synaptic weights and Bayes inference}

1. Nessler : If the STDP-induced changes in
synaptic strength depend in a particular way on the current
synaptic strength, STDP approximates for each synapse exponentially fast the conditional probability that the presynaptic neuron
has fired just before the postsynaptic neuron (given that the
postsynaptic neuron fires). This principle suggests that synaptic
weights can be understood as conditional probabilities, and the
ensemble of all weights of a neuron as a generative model for high-dimensional inputs that - after learning - causes it to fire with a
probability that depends on how well its current input agrees with
this generative model. The concept of a generative model is well
known in theoretical neuroscience [26,27]
 In a Bayesian inference context, every input
spike provides evidence for an observed variable, whereas every
output spike represents one stochastic sample from the posterior
distribution over hidden causes encoded in the circuit.

2.Nessler showed that STDP is able to approximate expectation maximization, by creating implicit generative models in the synaptic weights.

3. this is unsupervised learning, output neurons autonomously specialize on a hidden cause (due to learning rule)

\section{Mathematical model}

... wobei, das geh√∂rt wahrscheinlich eher in an den anfang vom experiment chapter? Weils ja kein "Background" ist, sondern "foreground"
3. generell meine Methoden...