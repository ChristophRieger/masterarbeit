@article{nessler,
    doi = {10.1371/journal.pcbi.1003037},
    author = {Nessler, Bernhard AND Pfeiffer, Michael AND Buesing, Lars AND Maass, Wolfgang},
    journal = {PLOS Computational Biology},
    publisher = {Public Library of Science},
    title = {Bayesian Computation Emerges in Generic Cortical Microcircuits through Spike-Timing-Dependent Plasticity},
    year = {2013},
    month = {04},
    volume = {9},
    url = {https://doi.org/10.1371/journal.pcbi.1003037},
    pages = {1-30},
    number = {4},

}

@article{HierachicalBayesVisualCortex,
 doi = {doi: 10.1364/josaa.20.001434},
    author = {Lee TS, Mumford D.},
    journal = {J Opt Soc Am A Opt Image Sci Vis},
    title = {Hierarchical Bayesian inference in the visual cortex},
    year = {2003},
    month = {07},
}

@article{neuralSubstrate,
 doi = {doi: 10.1038/nn.4390},
    author = {Funamizu Akihiro, Kuhn Bernd, Doya Kenji},
    journal = {Nature Neuroscience},
    volume = {19},
    title = {Neural substrate of dynamic Bayesian inference in the cerebral cortex},
    year = {2016},
    month = {12},
}

@ARTICLE{anatomyOfInference,
  
AUTHOR={Parr, Thomas and Friston, Karl J.},   
	 
TITLE={The Anatomy of Inference: Generative Models and Brain Structure},      
	
JOURNAL={Frontiers in Computational Neuroscience},      
	
VOLUME={12},           
	
YEAR={2018},      
	  
URL={https://www.frontiersin.org/articles/10.3389/fncom.2018.00090},       
	
DOI={10.3389/fncom.2018.00090},      
	
ISSN={1662-5188},   
   
ABSTRACT={To infer the causes of its sensations, the brain must call on a generative (predictive) model. This necessitates passing local messages between populations of neurons to update beliefs about hidden variables in the world beyond its sensory samples. It also entails inferences about how we will act. Active inference is a principled framework that frames perception and action as approximate Bayesian inference. This has been successful in accounting for a wide range of physiological and behavioral phenomena. Recently, a process theory has emerged that attempts to relate inferences to their neurobiological substrates. In this paper, we review and develop the anatomical aspects of this process theory. We argue that the form of the generative models required for inference constrains the way in which brain regions connect to one another. Specifically, neuronal populations representing beliefs about a variable must receive input from populations representing the Markov blanket of that variable. We illustrate this idea in four different domains: perception, planning, attention, and movement. In doing so, we attempt to show how appealing to generative models enables us to account for anatomical brain architectures. Ultimately, committing to an anatomical theory of inference ensures we can form empirical hypotheses that can be tested using neuroimaging, neuropsychological, and electrophysiological experiments.}
}

@ARTICLE{nesslerClone,
  author={Guo, Shangqi and Yu, Zhaofei and Deng, Fei and Hu, Xiaolin and Chen, Feng},
  journal={IEEE Transactions on Cybernetics}, 
  title={Hierarchical Bayesian Inference and Learning in Spiking Neural Networks}, 
  year={2019},
  volume={49},
  number={1},
  pages={133-145},
  keywords={Bayes methods;Integrated circuit modeling;Neurons;Computational modeling;Biological system modeling;Hidden Markov models;Biological neural networks;Hierarchical Bayesian model;mean field theory;spike-timing-dependent plasticity (STDP);spiking neural network;variational expectation maximization;winner-takes-all (WTA) circuits},
  doi={10.1109/TCYB.2017.2768554}
  }
  
@ARTICLE{STDPDAN,
  author={Dan Yang, Poo Mu-Ming},
  journal={Neuron}, 
  title={Spike timing-dependent plasticity of neural circuits}, 
  year={2004},
  volume={44},
  pages={23-30},
  doi={10.1016/j.neuron.2004.09.007}
  }
  
@article{STDPFELDMAN,
title = {The Spike-Timing Dependence of Plasticity},
journal = {Neuron},
volume = {75},
number = {4},
pages = {556-571},
year = {2012},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2012.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S0896627312007039},
author = {Daniel E. Feldman},
abstract = {In spike-timing-dependent plasticity (STDP), the order and precise temporal interval between presynaptic and postsynaptic spikes determine the sign and magnitude of long-term potentiation (LTP) or depression (LTD). STDP is widely utilized in models of circuit-level plasticity, development, and learning. However, spike timing is just one of several factors (including firing rate, synaptic cooperativity, and depolarization) that govern plasticity induction, and its relative importance varies across synapses and activity regimes. This review summarizes this broader view of plasticity, including the forms and cellular mechanisms for the spike-timing dependence of plasticity, and, the evidence that spike timing is an important determinant of plasticity in vivo.}
}

@BOOK{SpikingNeuronModelsBook, place={Cambridge}, title={Spiking Neuron Models: Single Neurons, Populations, Plasticity}, publisher={Cambridge University Press}, author={Gerstner, Wulfram and Kistler, Werner M.}, year={2002}}


@ARTICLE{softWTA,
  author={Rodney J Douglas, Kevan A C Martin},
  journal={Annual review of neuroscience}, 
  title={Neuronal circuits of the neocortex}, 
  year={2004},
  volume={27},
  pages={419-451},
  doi={10.1146/annurev.neuro.27.070203.144152}
  }
  
  @article{WTAPower,
    author = {Maass, Wolfgang},
    title = "{On the Computational Power of Winner-Take-All}",
    journal = {Neural Computation},
    volume = {12},
    number = {11},
    pages = {2519-2535},
    year = {2000},
    month = {11},
    abstract = "{This article initiates a rigorous theoretical analysis of the computational power of circuits that employ modules for computing winner-take-all. Computational models that involve competitive stages have so far been neglected in computational complexity theory, although they are widely used in computational brain models, artificial neural networks, and analog VLSI. Our theoretical analysis shows that winner-take-all is a surprisingly powerful computational module in comparison with threshold gates (also referred to as McCulloch-Pitts neurons) and sigmoidal gates. We prove an optimal quadratic lower bound for computing winner-takeall in any feedforward circuit consisting of threshold gates. In addition we show that arbitrary continuous functions can be approximated by circuits employing a single soft winner-take-all gate as their only nonlinear operation.Our theoretical analysis also provides answers to two basic questions raised by neurophysiologists in view of the well-known asymmetry between excitatory and inhibitory connections in cortical circuits: how much computational power of neural networks is lost if only positive weights are employed in weighted sums and how much adaptive capability is lost if only the positive weights are subject to plasticity.}",
    issn = {0899-7667},
    doi = {10.1162/089976600300014827},
    url = {https://doi.org/10.1162/089976600300014827},
    eprint = {https://direct.mit.edu/neco/article-pdf/12/11/2519/814328/089976600300014827.pdf},
}

@ARTICLE{hierarchicalBrain,
  
AUTHOR={Meunier, David and Lambiotte, Renaud and Fornito, Alex and Ersche, Karen and Bullmore, Edward},   
	 
TITLE={Hierarchical modularity in human brain functional networks},      
	
JOURNAL={Frontiers in Neuroinformatics},      
	
VOLUME={3},           
	
YEAR={2009},      
	  
URL={https://www.frontiersin.org/articles/10.3389/neuro.11.037.2009},       
	
DOI={10.3389/neuro.11.037.2009},      
	
ISSN={1662-5196},   
   
ABSTRACT={The idea that complex systems have a hierarchical modular organization originated in the early 1960s and has recently attracted fresh support from quantitative studies of large scale, real-life networks. Here we investigate the hierarchical modular (or “modules-within-modules”) decomposition of human brain functional networks, measured using functional magnetic resonance imaging in 18 healthy volunteers under no-task or resting conditions. We used a customized template to extract networks with more than 1800 regional nodes, and we applied a fast algorithm to identify nested modular structure at several hierarchical levels. We used mutual information, 0 < I < 1, to estimate the similarity of community structure of networks in different subjects, and to identify the individual network that is most representative of the group. Results show that human brain functional networks have a hierarchical modular organization with a fair degree of similarity between subjects, I = 0.63. The largest five modules at the highest level of the hierarchy were medial occipital, lateral occipital, central, parieto-frontal and fronto-temporal systems; occipital modules demonstrated less sub-modular organization than modules comprising regions of multimodal association cortex. Connector nodes and hubs, with a key role in inter-modular connectivity, were also concentrated in association cortical areas. We conclude that methods are available for hierarchical modular decomposition of large numbers of high resolution brain functional networks using computationally expedient algorithms. This could enable future investigations of Simon's original hypothesis that hierarchy or near-decomposability of physical symbol systems is a critical design feature for their fast adaptivity to changing environmental conditions.}
}



